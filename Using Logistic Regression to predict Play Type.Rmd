---
title: "Predicting Type of Play in the National Football League using Logistic Regression Machine Learning Algorithm"
output: html_document
date: "2023-07-02"
---

# Predicting  Type of Play in the National Football League using Logistic Regression Machine Learning Algorithm

```{r}
library(sjlabelled)
library(labelled)
library(janitor)
library(nflfastR)
library(tidyverse)
library(gtsummary)
```

I will be using supervised learning algorithms to predict the categorical outcome of a play in the National Football League using 2009 to 2023 play-by-play NFL data provided by nflfastR.  I see the future of the NFL to have data scientists with fast computing machines to predict real time the next play. Would this ruin the game? Maybe. But I am confident that football, a sport that is dear to my heart, will become more exciting as time goes on. 


### Load Data
```{r}
pbp <- load_pbp(c(2020:2022)) 
```

```{r}
data <- pbp %>%
  select(game_id, desc, home_team, away_team,season_type, play_type,ydstogo, qtr, down, game_seconds_remaining,
         yardline_100, yrdln, drive, season, season_type, away_score, home_score, rush_attempt, pass_attempt) %>%
  filter(rush_attempt == 1 | pass_attempt == 1) %>%
  filter(play_type == "pass" | play_type == "run") %>% # onyl want to predict pass or run 
  mutate(game_state = case_when(away_score > home_score ~ 0,
                                away_score < home_score ~ 1,
                                away_score == home_score ~2 )) %>%
  set_value_labels(game_state = c("Away Team Up" = 0,
                                     "Home Team Up" = 1,
                                     "Tie" = 2))

```

### Factor categorical variables 
```{r}
data_logreg <- data %>%
  mutate(play_type_factor = recode(play_type,
    "pass" = 1,
    "run" = 0
  )) %>%
   mutate(play_type_factor = as.factor(play_type_factor), #outcome variable
         qtr_factor = as.factor(qtr),
         down_factor = as.factor(down)
  ) 
```

Training Data
```{r}
library(caret)
Train <- createDataPartition(data_logreg$play_type_factor, p=.6, list = FALSE)
training <- data_logreg[Train,]
testing <- data_logreg[-Train,]
```

Logistic Regression Model
```{r}
mylogit <- glm(play_type_factor ~ qtr_factor + down_factor+ drive + ydstogo + game_seconds_remaining,
               family = "binomial",
               data = data_logreg)
```

All my variables seem to be statistically significant. Am I overfitting or did my literature review and NFL background pay off? Should run more model diagnostics to confirm. 
```{r}
tbl_regression(mylogit, exponentiate = TRUE)
```

3rd quarter makes it more likely to rush (which makes sense because usually teams will only have a few yards to go after 2 downs)


Let's take a look at the confidence intervals 
```{r}
confint(mylogit)
```

Predicted probabilities and graph them with their standard errors to produce a confidence interval 
```{r}
newdata <- predict(mylogit, 
                        newdata = testing,
                        type = "link",
                        se = TRUE)

#i get an error. so now i need to make the make them a dataframe
df1<- data.frame(matrix(unlist(newdata$fit), ncol = 1 , byrow = TRUE))
df2 <- data.frame(matrix(unlist(newdata$se.fit), ncol = 1 , byrow = TRUE))
df3 <- data.frame(matrix(unlist(newdata$residual.scale), ncol = 1 , byrow = TRUE))
df4 <- bind_cols(df1,df2,df3)

colnames(df4)[1] = "fit"
colnames(df4)[2] = "se.fit"
colnames(df4)[3] = "residual.scale"

newdata3 <- cbind(testing, df4)
newdata3 <- within(newdata3, {
    PredictedProb <- plogis(fit)
    LL <- plogis(fit - (1.96 * se.fit))
    UL <- plogis(fit + (1.96 * se.fit))
})
```

```{r}
head(newdata3, 5)
```

Looks like the predicted probability goes down as the yards to go increases
The predicted probability is highest with the first down 
```{r}
newdata3 %>%
  drop_na(down_factor) %>%
ggplot(aes(x = ydstogo , y = PredictedProb)) + 
  geom_ribbon(aes(ymin = LL, ymax = UL, fill = down_factor), alpha = 0.2) + 
  geom_line(aes(colour = down_factor), 
            size = 1)


```
Confusion Matrix

```{r}
library(caret)
pred <- predict(mylogit,
                     testing,
                     type ="response")
# If p exceeds threshold of 0.5, 1 else 0
play_type_pred <- ifelse(pred > 0.5, 1, 0)

# Convert to factor: p_class
p_class <- factor(play_type_pred, levels = levels(testing[["play_type_factor"]]))



accuracy <- table(p_class, testing$play_type_factor)
sum(diag(accuracy))/sum(accuracy)

confusionMatrix(data = p_class,  #predicted classes
                reference = testing$play_type_factor) #true results ) 

```

The accuracy of our predicted model is 63% ! Not bad but we can do better. 
Let's try Naive Bayes, KNN, Decision Tree, Random Forest, & Kernal Support Vector Machine next. 




